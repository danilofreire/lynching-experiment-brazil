\documentclass[a4paper,12pt]{article}
\usepackage{anysize}
\usepackage[T1]{fontenc}
\usepackage[stable]{footmisc}
\usepackage{setspace}
\usepackage{lmodern}
\usepackage{libertine}
\usepackage[libertine]{newtxmath}
\usepackage[scale=0.825]{FiraMono}
\usepackage[top=2cm,bottom=2cm,left=2cm,right=2cm]{geometry}
\usepackage{mathtools}
\usepackage[authoryear]{natbib}
\usepackage[UKenglish]{babel}
\usepackage[UKenglish]{isodate}
\usepackage{babelbib}
\usepackage{graphicx}
\usepackage{booktabs, makecell, longtable}
\usepackage{dcolumn}
\usepackage{float}
\usepackage[caption = false]{subfig}
\floatplacement{figure}{H}
\usepackage{caption}
\usepackage{rotating}
\usepackage{pdflscape}
\usepackage{pdflscape}
\newcommand{\blandscape}{\begin{landscape}}
\newcomman{\elandscape}{\end{landscape}}
\usepackage{ifthen}
\usepackage{graphicx}
\usepackage{markdown}
\usepackage[usenames,dvipsnames]{xcolor}
\definecolor{darkblue}{rgb}{0.0,0.0,0.55}
\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows}
\setcitestyle{aysep={}}
\usepackage{etoolbox}
\makeatletter
\patchcmd{\NAT@citex}
  {\@citea\NAT@hyper@{%
	 \NAT@nmfmt{\NAT@nm}%
	 \hyper@natlinkbreak{\NAT@aysep\NAT@spacechar}{\@citeb\@extra@b@citeb}%
	 \NAT@date}}
  {\@citea\NAT@nmfmt{\NAT@nm}%
   \NAT@aysep\NAT@spacechar\NAT@hyper@{\NAT@date}}{}{}
\patchcmd{\NAT@citex}
  {\@citea\NAT@hyper@{%
	 \NAT@nmfmt{\NAT@nm}%
	 \hyper@natlinkbreak{\NAT@spacechar\NAT@@open\if*#1*\else#1\NAT@spacechar\fi}%
   {\@citeb\@extra@b@citeb}%
	 \NAT@date}}
  {\@citea\NAT@nmfmt{\NAT@nm}%
   \NAT@spacechar\NAT@@open\if*#1*\else#1\NAT@spacechar\fi\NAT@hyper@{\NAT@date}}
  {}{}
\makeatother
\cleanlookdateon
\exhyphenpenalty=1000
\hyphenpenalty=1000
\widowpenalty=1000
\clubpenalty=1000
\usepackage{hyperref}

\hypersetup{
	breaklinks=true,
	linkcolor=Mahogany,
	citecolor=Mahogany,
	urlcolor=darkblue,
	colorlinks=true}

\newcommand*\justify{%
  \fontdimen2\font=0.4em% interword space
  \fontdimen3\font=0.2em% interword stretch
  \fontdimen4\font=0.1em% interword shrink
  \fontdimen7\font=0.1em% extra space
  \hyphenchar\font=`\-% allowing hyphenation
}

\begin{document}

\doublespacing

\noindent \textbf{Research \& Politics}

\noindent \today 

\vspace{.5cm}

\noindent Dear Editor and Reviewers,

\vspace{.5cm}

We would like to thank you for the opportunity to revise our manuscript,
``Vigilantism and Institutions: Understanding Attitudes toward Lynching in
Brazil'' (Ms. No. RAP-22-0164). Following the comments and suggestions of the
editors and reviewers, we have thoroughly revised our research letter and we
believe it has improved significantly as a result. 




We were especially committed to increasing the appeal of our research note to BJPolS's readership, emphasising the dialogue between our findings and those in the literature. We did this by extensively editing the Introduction and Discussion sections. We expand the literature review and add more references to the original theory as recommended by the editor and Reviewers 1 \& 2. We detail how the latest papers on the relationship between legislative size and public expenditure frame that debate and attempt to resolve it. We have also moved the references to our methodology from the Introduction to the Data and Methods section, as per the suggestion of Reviewer 2, to dedicate more space to theoretical issues. In the Discussion, having presented our results, we further specify the reasons why we believe past results have been highly heterogeneous. Lastly, we recommend possible avenues for further research that follow from our analyses, such as testing combinations of variables that we did not find in our search or measuring how domestic factors like gerrymandering or party effects influence the dynamics of the "law of $1/n$".

Following Reviewer 3's proposition, we conducted two new paper searches to broaden the scope of our previous query. In the first search, we ran a keyword-based query on Google Search to look for articles that discuss the "law of $1/n$" but do not cite \citet{weingast1981political}. We also checked the personal websites of the authors we had previously included in the paper in order to find unpublished research on our topic of interest. We thank Reviewer 3 for their insightful comment, as we included 2 new articles in our analysis as a result.

Throughout the paper, we clarify all of Reviewer 1 \& 2's questions about our independent variables, coding procedures, and modelling techniques. We have also changed our model specifications to more properly account for effect size independence, following Reviewer 2's critique. We identified the sources of dependence in our sample and adopted multilevel random effects models in all of our estimations. We are extremely appreciative of this recommendation, as it is now an important methodological strength in our paper.

When it comes to our results, we follow Reviewer 2's insight on how to interpret the evolution of research designs, toning down the idea that most of the variation in our estimates derives from methodological choices. We also present new results by adding a moderator for unicameralism, following Reviewer 1's reference. 

Below we discuss these changes in further detail, as well as the other
improvements we have done to the paper in response to the editors' and
reviewers' comments. We are pleased with the outcome and hope to have satisfied
all of your concerns. Again, we thank the editor for the opportunity to revise
our manuscript, and the reviewers for their immensely valuable comments.

\vspace{.5cm}

\noindent Yours Truly, 

\vspace{.5cm}

\noindent The Authors

\section*{Editor Comments and Responses}

\textbf{1)} The editor writes: ``The Reviewers provide helpful comments. Specifically, Reviewer 1 suggests that you re-frame the paper to acknowledge that the inconsistency of the results has long been understood in the literature, and that the search for explanations of that inconsistency is an important driver of that literature. Please give further thought to the key contribution of your meta-analysis against that background, as Reviewers 1 and 2 suggest, and discuss the theoretical contribution and its meaning more fully in the introduction and conclusion.''

\vspace{.3cm}

\noindent \textbf{Response:} 
\begin{quote}
    We have completely restructured the Introduction and Discussion sections to establish a better dialogue with the literature. We better contextualise our motivation to write this piece and more concretely demonstrate the implications of our results regarding previous findings. To illustrate the theory, we have provided the reader with a brief summary of the "law of $1/n$" model in Section A of the Supplementary Materials. We have also expanded the literature review in the Introduction. In the Discussion section, our hypotheses on the sources of heterogeneity are more clearly connected with the themes previously explored in the literature.
    
    We refer to these changes more specifically in our responses to Reviewer 1 in page 3, and to Reviewer 2 in page 7 of this document.
\end{quote}

\vspace{.3cm}

\noindent \textbf{2)} The editor writes: ``All Reviewers also provide detailed comments on your empirical analysis. Reviewer 3 has useful suggestions regarding your sampling strategy; Reviewers 1 and 2 focus on your dependent and explanatory variable. Please address these comments.'' 

\vspace{.3cm}

\noindent \textbf{Response:} 
\begin{quote}
    We have followed Reviewer 3's suggestion and nearly tripled the amount of records we assessed for eligibility, seeking articles within the distributive politics literature through broader criteria. Thanks to this review, we added two new articles to our meta-analysis.
    
    The main methodological adaptation we made was in response to Reviewer 2's extremely valuable comment on the need for using multilevel models. We are extremely grateful for this comment, and we thank Reviewer 2 for pointing out this crucial aspect in our empirical strategy.
    
    We also added a series of clarifications regarding our coding procedures, specially regarding the independent variables. We specify where these explanations can be found in the main article along this letter, according to each of the specific suggestions the Reviewers made.
\end{quote}

\vspace{.3cm}

\noindent \textbf{3)} The editor writes: ``Reviewers 1 and 2 also ask you to make better use of the Supplementary Materials (SI). In your main text, please refer to specific sections in the SI, please explain your results in the SI, and leave out the R code, which should be made publicly available separately from the SI with the replication materials.''

\vspace{.3cm}

\noindent \textbf{Response:} 
\begin{quote}
    We have made the changes requested by Reviewers 1 and 2 accordingly. The ``Supplementary Materials'' we refer to hereinafter contain only a discussion of the \citet{weingast1981political} and \citet{primo2008distributive} models in Section A, a detailed description of the search and eligibility procedures for study inclusion (Sections B and C), a guide to how we built the meta-analysis dataset from our pool of diverse coefficients (Section D), a presentation of the descriptive statistics of the included articles (Sections E and F), and the results for the binomials tests, meta-analyses, and meta-regressions (Sections G through K). The R scripts we previously presented along with this information are now in a different document referred to as ``Replication Materials''. For the purpose of reproducibility, the full datasets listing all the records we assessed and the stage and reason for each exclusion are also available online for consultation in the article's GitHub repository. 
\end{quote}

\vspace{.3cm}

We would like to thank the editors for their helpful comments and suggestions.

\section*{Reviewer 1 Comments and Responses}

\noindent \textbf{1)} Reviewer 1 writes: ``It has long been known that the empirical results are inconsistent in this literature. To wit, a major theme in the empirical literature -- at least for the last decade or so -- has been to try to explain the previously inconsistent findings, especially between upper and lower chambers; papers like Chen and Malhotra, Crowley, Lee, etc. take it as a main motivation to explain these inconsistencies. There have also been theoretical contributions in this vein, such as Pecorino's 2018 piece in Public Choice. In other words, these various approaches the authors note have been evolving not just as new techniques have been made available, but precisely *because* of the inconsistency in the findings the authors are discussing here. While I understand this paper is endeavoring to be concise, some service should be paid to a fuller discussion of the trends in the literature--noting that the previous authors in this literature were well aware of its inconsistent results--beyond just changes in methodology.''

\vspace{.3cm}

\noindent \textbf{Response:} 
\begin{quote}
    Reviewer 1 makes an excellent point. We agree that we had not properly expressed how more recent works identified and searched for strategies that solved the discrepancies in the literature. We have changed the framing of the paper so it is clear that scholars were well aware of the heterogeneity, and that our contribution in this sense is to quantitatively find the sources of such variation. While this idea permeates the Introduction section, here is one sentence we added that specifically addresses this point (p.2): 
    
    ``\textit{In this respect, scholars have long been aware of the theoretical and empirical limitations of the ``law of $1/n$'', and the proliferation of new studies reflect a conscious attempt to assess the robustness of the theory.}''
    
    As mentioned above, we have also expanded the literature review from paragraphs 1 through 3 in the Introduction section (p.2) as follows:
    
    ``\textit{Early studies that empirically tested the "law of $1/n$", as the theory is currently known, indeed found a positive correlation between the number of legislature seats and different measures of government spending, although these first results were mainly based on US state legislatures and the effect was often limited to one house (e.g., \citet{baqir2002districting, gilligan1995deviations, gilligan2001fiscal}).} 

    \textit{Later research, however, has questioned the validity of the "law of $1/n$". \citet{primo2008distributive} affirm that, due to spatial spillovers, a collection of small districts can supply public goods more efficiently than the central government. The authors conclude that a "reverse law of $1/n$" may hold, wherein a higher number of legislators in small constituencies decrease the overall public spending. Similarly, \citet{primo2006stop} and \citet{chen2007law} find that lower and upper chambers may have mixed effects on government spending, while \citet{petterssonlidbom2012size} argues that the impact of larger chamber sizes is negative when using data from Finland and Sweden.}

    \textit{Since many empirical tests of the "law of $1/n$" have produced conflicting results, scholars have expanded this research agenda and closely investigated how institutional factors condition the original formulation of the theory. For instance, authors such as \citet{crowley2019law} and \citet{pecorino2018supermajority} accurately point out that collective action problems have been overlooked in the literature, and recent findings indicate that bicameralism \citep{maldonado2013legislatures}, intergovernmental competition \citep{crowley2015local}, redistricting \citep{lee2018court}, and party ideology \citep{bjedov2014impact} strongly influence the relationship between seats and spending. Moreover, the literature has increasingly applied causal inference methods to estimate the effect of the "law of $1/n$", and in contrast to previous studies using panel data, regression discontinuity designs generally indicate that more legislators decrease public expenditures \citep{debenedetto2018effect, hohmann2017effect, lewis2019legislature, petterssonlidbom2012size}.}''
\end{quote}

\vspace{.3cm}

\noindent \textbf{2)} Reviewer 1 writes: ``In the empirical exercise, the authors routinely reference separating the empirical studies they use as their sample based on the "main explanatory variable." For instance, in section 3.3. This strikes me as problematic (or at least poorly explained) because it is typically standard in this literature (at least for those studies on bicameral legislatures such as cross-state studies on the US) to include both the upper and lower chamber size variables. So it is unclear to me how such a study would have a "main explanatory variable." This needs to be more clearly explained.''

\vspace{.3cm}

\noindent \textbf{Response:} 
\begin{quote}
    We agree that our explanations regarding the choice and use of the variables of interest were insufficient. When studies use evidence from bicameral legislatures, we included the coefficients for both upper and lower chamber size in all our samples. This is the case for thirteen articles in our analysis. Using data from both chambers is one of the reasons why our restricted sample contains 45 coefficients for a total of 30 papers. We added clarifications regarding our choice of independent variable in the first paragraph of the Data and Methods section, on page four.
    
    A specific comment on variable choice in bicameral systems is in footnote \#2. It reads: ``\textit{Since much of the literature estimates how institutional designs affect this relationship, ours and many other articles use both lower and upper chamber sizes as main explanatory variables.}''
\end{quote}

\vspace{.3cm}

\noindent \textbf{3)} Reviewer 1 writes: ``In Table 3, the authors also only present N and log(N) results; K is not indicated—was it an excluded group? If so, this needs to be made clear.''

\vspace{.3cm}

\noindent \textbf{Response:} 
\begin{quote}
    We acknowledge that Table 3 did not display the reference categories clearly enough. We have highlighted the notes below the table so the reader can have a more straightforward interpretation of the estimates. They present the reference category for each variable and moderator in the meta-regressions. For the independent variable, the reference category was upper chamber size, which is why this category was omitted in the table.
\end{quote}

\vspace{.3cm}

\noindent \textbf{4)} Reviewer 1 writes: ``Further, it is not clear to the reader why the authors use lower chamber size, upper chamber size, and then a log of only lower chamber size. Are there no studies which employ a log of upper chamber size?''

\vspace{.3cm}

\noindent \textbf{Response:} 
\begin{quote}
    Following the reviewer's remark, we double checked our study sample and confirm that the natural logarithm of upper chamber size is not present in any papers. As mentioned above, we included clarifications about our choice of independent variable in the first paragraph of the Data and Methods section (p.4). Footnote \#2 reads: ``\textit{We did not find any article that used the natural logarithm of upper chamber size in their models.}''
\end{quote}

\vspace{.3cm}

\noindent \textbf{5)} Reviewer 1 writes: ``How did the authors handle those studies in this literature which focused on unicameral legislatures? Were these grouped in with the "lower chamber" studies? Were they excluded? This is not clearly explained in the paper. In general, the results on unicameral legislatures tend to support the law of $1/n$.''

\vspace{.3cm}

\noindent \textbf{Response:} 
\begin{quote}
    As noted above, we agree that important details about data collection and coding were missing. Unicameral legislature sizes were coded under lower chamber size or natural logarithm of lower chamber size. Many studies consider lower chambers and unicameral legislatures as analogous institutions for quantitative purposes. An example is one of the papers in our meta-analysis \citep{stein1998institutional}. We expand the explanations surrounding the treatment of independent variables in the first paragraph of the Data and Methods section. A specific clarification on unicameral legislatures is in Footnote \#2. It reads: ``\textit{There are a few important nuances concerning coding of these variables. Unicameralism, for example, is captured both by lower chamber size ($n = 7$) and by log lower chamber size ($n = 5$).}''
    
    Upon reading this comment, we also acknowledged that although the differences between upper and lower chambers were so relevant to the discussion, we had not given enough attention to unicameral legislatures. Inspired by this remark, we coded a new moderator for institutional design. The categories were `Unicameral', for coefficients from purely unicameral systems; `Bicameral', for coefficients from purely bicameral systems; and `Mixed', for coefficients from studies that used samples which contained a mix of unicameral and bicameral systems. Examples of the latter were all the papers that used country-level data. Our findings confirm the Reviewer's insight: in the meta-regressions that aggregate all coefficients, unicameralism is a significant positive predictor of the $1/n$ effect. 
    
    Since this is an important finding, we discuss the Institutional Design moderator in all sections. The Data and Methods section presents under which category each article fits in Table 1, and its descriptive statistics in Table 2. In the first paragraph of the Meta-Regressions subsection, we explain how the variable is coded (p.12), and briefly interpret its results in the last paragraph (p.14).
    
    Because we found such interesting results in the meta-regressions, we decided to perform subgroup analyses with heterogeneous effects for unicameralism as well. The results can be found in section H.13 in the Supplementary Materials. We undertook tests similar to those we present in the article for Estimation Methods (p.12). Using the lower chamber size $\times$ per capita expenditure combination, we aggregated the data in two groups: one just for unicameral systems, and the other for all institutional designs excluding unicameralism. For unicameral systems, the estimates were mostly positive in the restricted sample, but none was statistically significant. Results were overwhelmingly positive for the extended sample, where they almost reached statistical significance. These results are in line with what we found in the rest of the paper, however they do not help us reach more robust conclusions on the effect of institutional design on the ``law of $1/n$''.
\end{quote}

\vspace{.3cm}

\noindent \textbf{6)} Reviewer 1 writes: ``The Supplementary Materials is full of content that is of very little use to the reader; even as an online appendix, there is no need to include roughly 100 pages of code from a statistical software. I believe the most relevant Supplementary Materials is the detailed discussion on selection.''

\vspace{.3cm}

\noindent \textbf{Response:} 
\begin{quote}
    We agree that the R script is useful to a limited amount of scholars, and not to the vast majority of readers. As mentioned above, we have separated the Supplementary Materials in two parts. The first follows Reviewer 1's recommendation, including a discussion of the theory, the study selection procedures, a description of how we coded the data in detail, and analysis results. The second gathers all scripts we use in each step of the study, and is aimed at those wishing to replicate our work or to produce new meta-analyses in the social sciences.
\end{quote}

\vspace{.3cm}

We would like to thank Reviewer 1 for her/his helpful comments and suggestions.

\section*{Reviewer 2 Comments and Responses}

\textbf{Major issues:}

\noindent \textbf{1)} Reviewer 2 writes: ``I believe the main framing of this manuscript should focus on explaining the interesting variation between studies (i.e., when do the law of 1/n or the reverse law are expected). From this perspective, the introduction part of the paper currently quickly jumps to the technicalities of the meta-analysis (e.g., a description of the two models used, measurement of DV etc.; see p. 2). These technical descriptions should appear in the method section. Instead, it would be more helpful to see some theoretical discussion on the reasons the literature proposes for the heterogeneity found in this study - even in a concise manner.''

\vspace{.3cm}

\noindent \textbf{Response:} 
\begin{quote}
    We agree that the technical discussion in the introductory section was misplaced. We have restructured the Introduction to fit Reviewer 1 and Reviewer 2's recommendations. As displayed above (p.4 of this letter), we expanded the literature review to capture the main points in the debate that dialogue with our findings. We have also made our critiques of the scholarship more clear, explicitly pointing to which we thought were the sources of heterogeneity in previous work in the Discussion section. Moreover, in Section A of the Supplementary Materials, we added a brief discussion of the theory developed by \citet{weingast1981political}, and also the "reverse law of $1/n$" by \citet{primo2008distributive}. 
\end{quote}

\vspace{.3cm}

\noindent \textbf{2.1)} Reviewer 2 writes: ``It is currently difficult to understand why many studies included in the meta-analysis have several effect sizes. Is it because of using different dependent? Some examples would help the readers.''

\vspace{.3cm}

\noindent \textbf{Response:} 
\begin{quote}
    In our restricted sample, a study can supply more than one coefficient if it employs more than one dependent or independent variable. Studies that analyse bicameral systems use upper chamber size and lower chamber size as independent variables, and thus supply two coefficients each. These studies are \citet{chen2007law, crowley2019law, gilligan2001fiscal, lee2015supermajority, lee2016supermajority, lee2018court, maldonado2013legislatures, ricciuti2003trading, ricciuti2004legislatures, primo2006stop}. The paper by \citet{bradbury2001legislative} alone supplies four coefficients, as they use two independent variables (upper chamber size and lower chamber size) and two dependent variables (expenditure as share of the GDP and per capita expenditure). Two other papers \citep{bjedov2014impact, erler2007termlimits} also use both of these dependent variables and only one independent (lower chamber size), supplying two coefficients each.
    
    To the extended sample, each paper can supply several coefficients because studies usually submit their data to a series of models where they include or exclude different controls or interaction terms, or perform slightly different tests. For instance, we drew twelve coefficients from \citet{fiorino2007legislature}. From a single table (Table 4) in their paper, we extracted four coefficients for the same variable combination (lower chamber size and per capita expenditure).
\end{quote}

\vspace{.3cm}

\noindent \textbf{2.2)} Reviewer 2 writes: ``Moreover, and more substantially, I am not sure how including studies with several effect sizes in a separate model (p. 7) can solve the violation of non-independent effect sizes, required in meta-analyses. The authors do not report the statistical models they used for solving these violations (I did not find it in the appendix either). There are various ways to address such issues, such as robust variance estimation (see Hedges et al., 2010) or using multi-level meta-analyses (see e.g. application in Matthes et al., 2019). 

Furthermore, since there were several studies focusing on the same country (e.g., 14 studies investigating the US), did they use the same samples in their analysis? If so, doesn't it violate the non-independence assumption on its own (as they use the same district ``sample'')? If that is the case, the authors should treat this effect size dependency also for the first model (with the 42 main coefficients). These issues are very important since some of the authors' findings are based only on the ``extended models'' in Table 3 (i.e., those including 142 effect sizes, even from studies reporting several effect sizes related to the same sample). If these findings are based on biased estimates, we should be a lot more cautious interpreting them.''

\vspace{.3cm}

\noindent \textbf{Response:} 
\begin{quote}
    As Reviewer 2 correctly notes, the coefficient extraction procedure we just presented in the previous response is the main source of effect size dependence in our extended sample analyses. An additional source of dependence is the fact that many studies analyse the same cases, sometimes even using the same data sources. The Reviewer is also correct to point out that separating the effect sizes into a restricted and an extended sample does not properly address the dependence of the coefficients within the extended sample. We followed the Reviewer's suggestion rigorously by employing multilevel random effect models \citep{cheung2014modeling, matthes2019meta} in all of our estimations. A thorough explanation of how we identified, grouped the studies that constitute the new levels, and coded them can be found in section H.1 of the Supplementary Materials. We describe the procedure more succinctly in the Data and Methods section in the main paper (last paragraph on page 7):
    
    ``\textit{We add two extra levels to the regular meta-analysis, one including a unique publication ID for each paper, and another indicating the data source used in the original study. By adding these two levels, we account for within- and between-study variation, thus removing these sources of effect size dependency and improving the accuracy of the results.}''
    
    We believe the inclusion of additional levels reduces the bias previously present in our analyses, producing far more reliable estimates. We are highly appreciative of this comment, as it has ignited major changes in our manuscript, severely improving the robustness of our results. 
\end{quote}

\vspace{.3cm}

\noindent \textbf{3)} Reviewer 2 writes: ``How did the authors convert the original studies' coefficients into standardized effect sizes? It is important to mention how the authors render these coefficients comparable due to the various research designs included in the meta-analysis.''

\vspace{.3cm}

\noindent \textbf{Response:} 
\begin{quote}
    We have included a paragraph in the Data and Methods section (p.7) to clarify the coefficient standardisation procedure. It reads:
    
    ``\textit{We use Hedges' $g$ to calculate effect sizes in our meta-analysis \citep{hedges1981distribution}. While there are other methods to standardise coefficients in meta-analytic studies, Hedges' $g$ corrects for upward bias in small sample sizes and is considered more robust than measures such as Cohen's $d$ \citep{lakens2013calculating}. We estimate the Standardised Mean Difference (SMD), which represents the effect size in each study relative to the variability observed in that study, by extracting the coefficients and the standard errors from all articles included in our sample and converting them to Hedges' $g$. In cases where authors did not report the standard errors for their estimates, we computed them using the t-statistic presented in the original tables.}''
\end{quote}

\vspace{.3cm}

\noindent \textbf{4)} Reviewer 2 writes: ``our results suggest that study coefficients are highly sensitive to research design choices'' (p. 13) - this is a rather bold statement (``highly sensitive'') since most differences between study designs are nonsignificant (on Table 3). I would tone down this argument much more and address its limitations in the discussion.'' 

\vspace{.3cm}

\noindent \textbf{Response:} 
\begin{quote}
    We have adapted the language when referring to the effects of estimation methods according to the Reviewer's suggestions throughout the paper. For instance, paragraph 6 of the Introduction (p.3) reads:
    
    ``\textit{However, when we look only at articles that employ regression discontinuity designs, we see that all four papers included in our sample suggest that a higher number of legislators leads to lower public spending \citep{debenedetto2018effect, hohmann2017effect, lewis2019legislature, petterssonlidbom2012size}. In this regard, it is possible that methodological choices partially explain the divergent results observed in the literature, as studies that use causal inference methods consistently point to the same direction. One limitation of this finding is that these studies only test the impact of lower house size on the natural logarithm of expenditure per capita, thus it remains unclear whether the results hold with other variables.}''
    
    The Results and Discussion sections present these findings more objectively. On page 14, we report the following conclusion regarding estimation methods: ``\textit{The meta-regressions confirm that modern estimation methods such as RDDs and panel/fixed-effects models decrease effects more frequently than OLS regressions.}''
\end{quote}

\vspace{.3cm}

\noindent \textbf{5)} Reviewer 2 writes: ``I encourage the authors to elaborate more on the implications of their results rather than to simply describe them, especially in the context of their moderators (electoral systems and possibly, the research design - but see my above concerns regarding the results related to study designs). Although the format should be concise, such a discussion will improve the readers' understanding of the main findings much more (especially non-expert readers). For example, the seemingly "methodological" explanation of research design as a moderator has substantial implications. If that is the case, to what extent can we lean on earlier studies that did not use causal inference?''

\vspace{.3cm}

\noindent \textbf{Response:} 
\begin{quote}
    Following Reviewer 2's recommendations, we have more appropriately framed the paper so that we discuss the institutional moderators and their relationship to the theory across the entire piece. Since we changed our model specifications and added a new moderator, our Results section was also significantly altered. We reduced the Meta-Analysis subsection (3.2) and expanded the Meta-Regressions subsection (3.3) to account for the most relevant and auspicious findings. In this sense, in paragraph 2 of subsection 3.3, we explain to the reader how she should interpret the meta-regression results. We believe this makes our arguments about the meta-regression results more compelling. We also added more substantive insights to accompany the description of meta-regression results in each paragraph of section 3.3. 
    
    We present and partly interpret our results in the Introduction section, reporting back to elements from the literature and to the theory. The last paragraph in the Introduction (p.3) reads:
    
    ``\textit{The meta-regressions provide additional evidence that our study sample is highly heterogeneous and that effect sizes differ substantially according to study specifications. When using an extended sample of 162 coefficients, we find that unicameralism is associated with higher public spending, as predicted by the ``law of $1/n$''. Since most unicameral legislatures in our sample are local governments (municipalities or districts), this result supports the predictions of \citet{weingast1981political}. Moreover, our meta-regressions indicate that larger upper chambers spend more in terms of per capita expenditure than lower chambers, a result that also appears in the binomial tests. Overall, non-majoritarian voting systems seem to decrease government spending, following the idea that the $1/n$ effect grows weaker as the empirical cases distance from the original definition of the law. Finally, meta-regression results confirm that regression discontinuity designs reduce public spending estimates.}''
    
    The Discussion section has also increased both in size and scope. Now, we more aptly establish the dialogue between our electoral system findings and the original theory and literature. For instance, in page 15, the following reads:
    
    ``\textit{While we believe that moving beyond the majoritarian districts framework could produce valuable insights, institutional features that are central to the theory cannot be overrun. For example, proportional representation (PR) electoral systems allow candidates whose constituents are spread across large territories to provide diffused public goods and win elections. However, geographically-targeted service provision is at the very core of the legislative behaviour that produces the "law of $1/n$". Thus, scholars should consider the possible implications of these micro-level dynamics when applying the "law of $1/n$" logic to different settings.}''
\end{quote}

\vspace{.3cm}

\noindent \textbf{More minor comments:}

\vspace{.3cm}

\noindent \textbf{1)} Reviewer 2 writes: ``Table 1 - it will be clearer to separate the notes at the bottom of the table into separate columns. For instance, note \#1 will explain the abbreviations of the Journal column note \#2 will refer to the Country column. Otherwise, the reader has to manually look for a given abbreviation out of the rather long list.''

\vspace{.3cm}

\noindent \textbf{Response:} 
\begin{quote}
    We agree this can be an unnecessary inconvenience to the reader. We have changed the notes in Table 1 according to the Reviewer's specifications. 
\end{quote}

\vspace{.3cm}

\noindent \textbf{2)} Reviewer 2 writes: ``Also regarding Table 1, I believe it will be more convenient to simply write the authors and the year of publication in the first column (e.g., "Stein et al., 1998") while keeping the table order as it is (according to the year of publication) - rather than splitting them into two columns. I am also not sure whether the title of the paper really helps the readers or simply confuses them (it makes the table less elegant in my opinion). I would delete the title (if a reader wishes to see the full reference, she can look it in the bibliography). In contrast, it will be more beneficial to mention inside the table the DVs used in each study (as currently explained in the body text; p. 6).''

\vspace{.3cm}

\noindent \textbf{Response:} 
\begin{quote}
    We have made these alterations to Table 1 accordingly. We also added a column for the new Institutional Design moderator.
\end{quote}

\vspace{.3cm}

\noindent \textbf{3)} Reviewer 2 writes: ``The use of $n$ and $k$ as signifiers of the independent variables is a bit confusing throughout the paper since in the meta-analyses domain, they usually signify the number of effect sizes ($k$) and the number of respondents per study ($n$). More broadly, it is even more confusing when discussing Table 3 (the reader has to remember what $n$ and $k$ represent, instead of simply writing the meanings) or when interpreting its results in the discussion part.''

\vspace{.3cm}

\noindent \textbf{Response:} 
\begin{quote}
    We agree that adding labels to variables is an unnecessary inconvenience to the reader. All references to the independent variables now translate their full meaning.
\end{quote}

\vspace{.3cm}

\noindent \textbf{4)} Reviewer 2 writes: ``I appreciate the authors' elaborated appendix, but the readers might get a bit lost without specific references to the sub-sections in it throughout the main paper: for example, not just referring to the Supplementary Materials in general, but to the specific section in it. Moreover, the authors should consider leaving out the R code from the online appendix, and simply anonymously upload it to an external open science source. For people who are not experts in R (and perhaps also for those who are), the combination of code and text can be a bit confusing.''

\vspace{.3cm}

\noindent \textbf{Response:} 
\begin{quote}
    As noted above, we agree that only a handful of scholars would be interested in R scripts, which get in the way of most readers. We have split the Supplementary Materials into two documents. The one we refer to as the ``Supplementary Materials'' includes a discussion of the theory, the study selection procedures, a description of how we treated the data in detail, and analysis results. The other collects all the R code we wrote for each stage of data collection and analysis. We recommend the latter is used by those wishing to replicate our work and strongly encourage peers to use it and produce new meta-analyses in the social sciences.
\end{quote}

\vspace{.3cm}

\noindent \textbf{5)} Reviewer 2 writes: ``To facilitate interpretation of Figure 1, it would be more convenient to number each plot, and refer to it in the body text (pp. 10-11).''

\vspace{.3cm}

\noindent \textbf{Response:} 
\begin{quote}
    All plots in Figures 1 and 2 are now individually numbered, and referred to in the body text.
\end{quote}

We would like to thank Reviewer 2 for her/his helpful comments and suggestions.

\section*{Reviewer 3 Comments and Responses}

\noindent \textbf{1)} Reviewer 3 writes: ``First, I am concerned about the first criterion for inclusion in the meta-analysis. Studies could only be included if they cited the Weingast et al. (1981) study. While I don't doubt that this work is foundational to the distributive politics literature, it is an unnecessary restriction. Are there any studies that fit the other two inclusion criteria but do NOT cite Weingast? Maybe there aren't any, but if there are, they should be included since they are still just as relevant to the question at hand. The second inclusion criterion is the most important: a study that quantitatively analyzes the variables of interest. This of course makes the literature search more difficult, but also more comprehensive, which is a main benefit of good meta-analyses.''

\vspace{.3cm}

\noindent \textbf{Response:} 
\begin{quote}
    The concern Reviewer 3 expresses is one we share. We address this comment by conducing a second round of record collection. We increased our breadth by using a search string with key terms on Google Scholar. We meant to capture all articles that approached the relationship between legislature size and public spending. The search string we used is the following:
    
    \texttt{\justify ("upper chamber size" OR "lower chamber size" OR "council size" OR "parliament size" OR "legislature size" OR "number of legislators" OR "legislative size") AND ("spending" OR "expenditure" OR "government size")}
    
    We fuzzy matched the resulting database with the one we had originally analysed to remove all entries we had already covered. As part of this eligibility analysis, we assessed an additional 3,042 records. The exclusion criteria and procedures were the exact same as those performed in the first round (for the original manuscript the Reviewers and Editors read). They are fully detailed in Sections B and C of the Supplementary Materials. The full dataset of excluded records is available for online consultation in the article's GitHub repository.
    
    Resulting from this second round of surveying the literature, we found two articles that satisfied all the criteria. They were thus included in our analysis. The new papers are \citet{coate2011government} and \citet{debenedetto2018effect}. We thank Reviewer 3 for this comment, as it has effectively made our survey more comprehensive. 
\end{quote}

\vspace{.3cm}

\noindent \textbf{2)} Reviewer 3 writes: ``Second, another main benefit of meta-analyses is to assess the possibility of publication bias. Studies are often more likely to be published if they find statistically significant effects in the direction that is expected, but a comprehensive search of ongoing studies allows meta-analysts to check this. In the current sample, only 4 papers are unpublished, but I also wonder if this is due to the restricted inclusion criteria. For example, if one uses the Google Scholar feature to find articles citing Weingast et al, that would only pick up papers that are already published in a journal or otherwise online, but it may miss any working papers that are not shared publicly. A more comprehensive search may result in more unpublished studies. Either way, can the authors include some sort of formal tests or visualizations for publication bias, such as funnel plots? I think if these two revisions could be made this paper would make a strong contribution.''

\vspace{.3cm}

\noindent \textbf{Response:} 
\begin{quote}
    We understand the Reviewer's concern with publication bias, and we accept both of her/his suggestions in this comment. First, so as not to miss any papers that have not been circulated as Working Papers, we seek after those that have been shared as ongoing projects. We looked into the personal webpages of the scholars who wrote all of the papers in our original sample of studies. In their personal platforms, we scouted for pieces of research about distributive politics. We targeted specifically those that had not been uploaded to large repositories and open archives such as SocArXiv, as those tend to appear in Google Scholar searches. We gathered 15 pieces of work with titles potentially related to our research topic and submitted them to the eligibility criteria. None of these papers were included in the final sample. This procedure is also explained in Section B of the Supplementary Materials, and a dataset displaying all records assessed and their reason for exclusion is available for online consultation as well.
    
    Attending to the Reviewer's second request, we add \citet{egger1997bias} funnel plots to assess publication bias in all of our meta-analyses. Funnel plots display the possibility of having a file-drawer effect, meaning they can indicate whether null results are under-represented in our sample or not. The funnel plots are available in the Supplementary Materials below the forest plot for each variable combination in the restricted and in the extended samples (Sections H and I). All but one of our \citet{egger1997bias} tests reject the hypothesis of publication bias.
\end{quote}

We would like to thank Reviewer 3 for her/his helpful comments and suggestions.


\newpage
\bibliography{references.bib}
\bibliographystyle{apalike}

\end{document}d
